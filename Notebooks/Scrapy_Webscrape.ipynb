{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T19:09:08.148762Z",
     "start_time": "2021-02-05T19:09:07.576817Z"
    }
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from progress.bar import Bar\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T19:09:09.575401Z",
     "start_time": "2021-02-05T19:09:09.568358Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_movies():\n",
    "     # Parse the page with beautiful soup\n",
    "    link_all_scripts = 'https://imsdb.com/all-scripts.html'\n",
    "    response_all_scripts = requests.get(link_all_scripts)\n",
    "    soup = BeautifulSoup(response_all_scripts.text, 'html.parser')\n",
    "\n",
    "    # This webpage is constructed with tables, the 3rd one is the one we want\n",
    "    find_tables = soup.find_all('td', valign='top')\n",
    "    all_movies = find_tables[2].findAll('a')\n",
    "\n",
    "    movies = [(movie_info.string, \\\n",
    "              movie_info[\"href\"], \\\n",
    "              re.split(\"[,.]\",movie_info.string)[0].replace(' ', '_'))\n",
    "              for movie_info in all_movies]\n",
    "    return movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T19:09:11.866632Z",
     "start_time": "2021-02-05T19:09:11.861504Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_movie_info(movies):\n",
    "\n",
    "    for movie in movies:\n",
    "        if movie[1][0:15] !='/Movie Scripts/':\n",
    "            return 'One of the movie link does not start with /Movie Scripts/.'\n",
    "    return 'All movie URLs have a correct format.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T19:09:12.517244Z",
     "start_time": "2021-02-05T19:09:12.482340Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    def handle_movie (movie, browser):\n",
    "        # Unpack tuple\n",
    "        title, link_to_movie_page, movie_title = movie\n",
    "\n",
    "        # Interrogate the page with all the movie information (ratings, writer,\n",
    "        # genre, link to script)\n",
    "        full_html_link = u'http://www.imsdb.com' + link_to_movie_page\n",
    "        response_script = requests.get(full_html_link)\n",
    "        soup = BeautifulSoup(response_script.text, 'html.parser')\n",
    "\n",
    "        # Get all relevant information (genre, writer, script) from page\n",
    "\n",
    "        list_links = soup.find_all('table', align=\"center\")[0].find_all('a')\n",
    "        \n",
    "    #     print(len(list_links))\n",
    "        genre = []\n",
    "        writer = []\n",
    "        script = ''\n",
    "        for link in list_links:\n",
    "            href = link['href']\n",
    "            if href[0:7]== \"/writer\":\n",
    "                writer.append(link.get_text())\n",
    "            if href[0:7]== \"/genre/\":\n",
    "                genre.append(link.get_text())\n",
    "                genre.append(\"//\")\n",
    "            if href[0:9]== \"/scripts/\":\n",
    "                script = href\n",
    "\n",
    "        # If the link to the script points to a PDF, skip this movie, but log\n",
    "        # the information in `movies_pdf_script.csv`\n",
    "        if script == '' or script[-5:] != '.html':\n",
    "            path_to_directory = '../data/scraping/'\n",
    "            pdf_logging_filename = path_to_directory + 'movies_pdf_script.csv'\n",
    "            with open(pdf_logging_filename, 'a') as f:\n",
    "                new_row = title + '\\n'\n",
    "                f.write(new_row)\n",
    "\n",
    "        # If the link to the script points to an html page, write the corresponding\n",
    "        # text to a file and include the movie in a csv file, with meta-information\n",
    "        else:\n",
    "\n",
    "            # Parse the webpage which contains the script text\n",
    "            full_script_url =  u'http://www.imsdb.com' + script\n",
    "            browser.get(full_script_url)\n",
    "            page_text = browser.page_source\n",
    "            soup = BeautifulSoup(page_text, 'html.parser')\n",
    "\n",
    "            # If the scraping does not go as planned (unexpected structure),\n",
    "            # log the file name in an error file\n",
    "            if len(soup.find_all('td', \"scrtext\"))!=1 or soup.find_all(\"title\") == \"404 Not Found\":\n",
    "                error_file_name = '../data/scraping/scraping_error.csv'\n",
    "                with open(error_file_name, 'a') as error_file:\n",
    "                    new_row = title + '\\n'\n",
    "                    error_file.write( new_row )\n",
    "\n",
    "            # Normal scraping:\n",
    "            else:\n",
    "                # Write the script text to a file\n",
    "                path_to_directory = '../data/scraping/texts/'\n",
    "                filename = path_to_directory + movie_title + '.txt'\n",
    "                text = soup.find_all('td', \"scrtext\")[0].get_text()\n",
    "                with codecs.open(filename, \"w\",\n",
    "                        encoding='ascii', errors='ignore') as f:\n",
    "                    f.write(text)\n",
    "\n",
    "                # Add the meta-information to a CSV file\n",
    "                path_to_directory = '../data/scraping/'\n",
    "                success_filename = path_to_directory + 'successful_files.csv'\n",
    "                new_row = title + ';' + str(genre) + ';' + str(writer) + ';' \\\n",
    "                        + movie_title + ';' + filename + '\\n'\n",
    "                with open(success_filename, 'a') as f:\n",
    "                    f.write(new_row)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T19:33:09.268425Z",
     "start_time": "2021-02-05T19:32:36.454704Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All movie URLs have a correct format.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "\n",
    "    # Create data/scraping/texts files\n",
    "    if not os.path.exists('../data'):\n",
    "        os.mkdir('../data')\n",
    "        print ('making ../data folder')\n",
    "    if not os.path.exists('../data/scraping'):\n",
    "        os.mkdir('../data/scraping')\n",
    "        print ('making ../data/scraping folder')\n",
    "    if not os.path.exists('../data/scraping/texts'):\n",
    "        os.mkdir('../data/scraping/texts')\n",
    "        print ('making ../data/scraping/texts folder')   \n",
    "        \n",
    "    # List all the available movies, and the corresponding URL links\n",
    "    movies = get_all_movies()\n",
    "    print (check_movie_info(movies))\n",
    "\n",
    "    \n",
    "    # Write all the scripts (in texts folder) and the summary of the movies\n",
    "    # in .csv format (in scraping folder)\n",
    "    browser = webdriver.Safari()\n",
    "    for idx,movie in enumerate(movies[1179:]):\n",
    "        handle_movie(movie, browser)\n",
    "        Bar(len(movies))      \n",
    "\n",
    "#stopping points [:822], [823:1167],[1168:1178], [1179:]\"\"\n",
    "    \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
